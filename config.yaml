embedder:
  provider: openai
  config:
    model: "text-embedding-3-large"
llm:
  provider: openai
  config:
    model: "gpt-4o-mini"
    temperature: 0.5
    max_tokens: 4096
    top_p: 1
    stream: true
